{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Sentiment\n",
    "\n",
    "This is the notebook for constructing Theano RNN layers and RNN sentiment classifier. The text for an encoder-decoder can be found in a lot of places, and one reference is here: [http://anie.me/rnn-encoder-decoder/](http://anie.me/rnn-encoder-decoder/). This notebook might also contain a section on vanilla RNN classification task, and a section on RNN autoencoder as well. Note in this implementation, we are being a lot more efficient than some blog posts (like in WildML)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from classifier.rnn_layers import *\n",
    "from classifier.util import *\n",
    "from data.sentiment_util import *\n",
    "from vis.util import *\n",
    "import numpy as np\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "  \"\"\" returns relative error \"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Loading Data Sentiment\n",
    "\n",
    "We use SNLI for inference task (the main purpose of encoder-decoder). We use a partial IMDB dataset provided by Yoon Kim (also preprocessed into numpy form)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading training sentences...\n",
      "loading dev sentences...\n",
      "loading test sentences...\n",
      "X_val <type 'numpy.ndarray'> (29904,) int32\n",
      "X_train <type 'numpy.ndarray'> (537264,) int32\n",
      "y_train <type 'numpy.ndarray'> (9594,) int32\n",
      "W_embed <type 'numpy.ndarray'> (18768, 300) float32\n",
      "X_test <type 'numpy.ndarray'> (29904,) int32\n",
      "y_val <type 'numpy.ndarray'> (534,) int32\n",
      "idx_word_map <type 'list'> 18768\n",
      "y_test <type 'numpy.ndarray'> (534,) int32\n",
      "word_idx_map <type 'dict'> 18768\n"
     ]
    }
   ],
   "source": [
    "data = load_data('data/rt_sentiment_data.npz', 'data/sentiment_vocab.json')\n",
    "\n",
    "# NOTE: right now this doesn't work, but we want to hold it to \n",
    "# the same standard as other code\n",
    "# Print out all the keys and values from the data dictionary\n",
    "for k, v in data.iteritems():\n",
    "  if type(v) == np.ndarray:\n",
    "    print k, type(v), v.shape, v.dtype\n",
    "  else:\n",
    "    print k, type(v), len(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the Data\n",
    "\n",
    "All the sentences in train, dev, and test are encoded already by indicies. Now we see if we can successfully decode them into actual sentence with our `decode()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ [3, 2, 83, 2, 11, 2, 1182, 2, 3184, 2, 37, 2, 3185, 2, 1008, 2, 517, 2, 87, 2, 81, 2, 84, 2, 26, 2, 198, 2, 128, 2, 3186, 2],\n",
       "       [19, 2, 3187, 2, 712, 2, 763, 2, 3188, 2, 74, 2, 3189, 2, 1529, 2, 3189, 2, 3190, 2, 420, 2, 660, 2, 1639, 2, 619, 2, 7, 2, 18, 2, 19, 2, 3191, 2, 68, 2, 2060, 2, 1068, 2, 255, 2, 81, 2, 21, 2, 118, 2, 1639, 2, 26, 2, 452, 2, 3192, 2, 26, 2, 452, 2, 1193, 2, 1726, 2, 3193, 2, 3194, 2],\n",
       "       [3195, 2, 5, 2, 2540, 2, 78, 2, 2768, 2, 14, 2, 19, 2, 443, 2, 208, 2, 2217, 2],\n",
       "       [87, 2, 11, 2, 659, 2, 19, 2, 2109, 2, 1795, 2, 402, 2, 14, 2, 19, 2, 410, 2, 204, 2],\n",
       "       [1768, 2, 26, 2, 3196, 2, 3197, 2, 825, 2]], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla RNN stepforward\n",
    "\n",
    "We implement the RNN for a single forward step in Theano. We adapted `rnn_stepforward` so it works with theano's special loop construct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next_h error:  9.608901251e-08\n"
     ]
    }
   ],
   "source": [
    "N, D, H = 3, 10, 4\n",
    "\n",
    "x = np.asarray(np.linspace(-0.4, 0.7, num=N*D).reshape(N, D), dtype='float32')\n",
    "prev_h = np.asarray(np.linspace(-0.2, 0.5, num=N*H).reshape(N, H), dtype='float32')\n",
    "Wx = np.asarray(np.linspace(-0.1, 0.9, num=D*H).reshape(D, H), dtype='float32')\n",
    "Wh = np.asarray(np.linspace(-0.3, 0.7, num=H*H).reshape(H, H), dtype='float32')\n",
    "b = np.asarray(np.linspace(-0.2, 0.4, num=H), dtype='float32')\n",
    "\n",
    "x_sym = T.matrix('x')\n",
    "prev_h_shared = theano.shared(\n",
    "            value=prev_h,\n",
    "            name='prev_h',\n",
    "            borrow=True\n",
    "        )\n",
    "Wx_shared = theano.shared(\n",
    "            value=Wx,\n",
    "            name='Wx',\n",
    "            borrow=True\n",
    ")\n",
    "Wh_shared = theano.shared(\n",
    "            value=Wh,\n",
    "            name='Wh',\n",
    "            borrow=True\n",
    ")\n",
    "b_shared = theano.shared(\n",
    "            value=b,\n",
    "            name='b',\n",
    "            borrow=True\n",
    ")\n",
    "\n",
    "next_h, _ = rnn_step_forward(x_sym, prev_h_shared, Wx_shared, Wh_shared, b_shared, 0, T.zeros((N, 1, H)))\n",
    "\n",
    "get_value_nexth = theano.function([x_sym], next_h)\n",
    "\n",
    "expected_next_h = np.asarray([\n",
    "  [-0.58172089, -0.50182032, -0.41232771, -0.31410098],\n",
    "  [ 0.66854692,  0.79562378,  0.87755553,  0.92795967],\n",
    "  [ 0.97934501,  0.99144213,  0.99646691,  0.99854353]])\n",
    "\n",
    "print 'next_h error: ', rel_error(expected_next_h, get_value_nexth(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theano `scan()` Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.   1.   4.   9.  16.  25.  36.  49.  64.  81.]\n",
      "[  0.00000000e+00   1.00000000e+00   1.60000000e+01   8.10000000e+01\n",
      "   2.56000000e+02   6.25000000e+02   1.29600000e+03   2.40100000e+03\n",
      "   4.09600000e+03   6.56100000e+03]\n"
     ]
    }
   ],
   "source": [
    "k = T.iscalar(\"k\")\n",
    "A = T.vector(\"A\")\n",
    "\n",
    "def power(prior_result, A):\n",
    "    return prior_result * A\n",
    "\n",
    "# Symbolic description of the result\n",
    "# Comment: interesting, so scan has a very high freedom\n",
    "# any variable of scan can be a symbolic variable passed in...\n",
    "# meaning, when we have RNN\n",
    "result, _ = theano.scan(fn=power,\n",
    "                              outputs_info=T.ones_like(A),  # handles initialization\n",
    "                              non_sequences=A,\n",
    "                              n_steps=k)\n",
    "\n",
    "# We only care about A**k, but scan has provided us with A**1 through A**k.\n",
    "# Discard the values that we don't care about. Scan is smart enough to\n",
    "# notice this and not waste memory saving them.\n",
    "final_result = result[-1]\n",
    "\n",
    "# compiled function that returns A**k\n",
    "power = theano.function(inputs=[A,k], outputs=final_result) # , updates=updates\n",
    "\n",
    "print(power(range(10),2))\n",
    "print(power(range(10),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2, 5)\n",
      "[[[-0.42070749 -0.27279261 -0.11074946  0.0574041   0.22236253]\n",
      "  [-0.55857474 -0.39065823 -0.19198182  0.02378407  0.23735671]]\n",
      "\n",
      " [[-0.39525807 -0.2255466  -0.04094539  0.14649412  0.32397318]\n",
      "  [-0.27150196 -0.07088803  0.13562937  0.33099726  0.50158769]]\n",
      "\n",
      " [[-0.42305112 -0.24223728 -0.04287028  0.15997045  0.35014525]\n",
      "  [-0.51014829 -0.3052443  -0.06755204  0.17806391  0.40333042]]]\n"
     ]
    }
   ],
   "source": [
    "# Now we try something slightly more complex:\n",
    "\n",
    "N, TS, D, H = 2, 3, 4, 5\n",
    "\n",
    "x = T.tensor3('x')\n",
    "\n",
    "x_num = np.asarray(np.linspace(-0.1, 0.3, num=N*TS*D).reshape(N, TS, D), dtype='float32')\n",
    "h0 = np.asarray(np.linspace(-0.3, 0.1, num=N*H).reshape(N, H), dtype='float32')\n",
    "Wx = np.asarray(np.linspace(-0.2, 0.4, num=D*H).reshape(D, H), dtype='float32')\n",
    "Wh = np.asarray(np.linspace(-0.4, 0.1, num=H*H).reshape(H, H), dtype='float32')\n",
    "b = np.asarray(np.linspace(-0.7, 0.1, num=H), dtype='float32')\n",
    "\n",
    "h0_shared = theano.shared(\n",
    "            value=h0,\n",
    "            name='h0',\n",
    "            borrow=True\n",
    "        )\n",
    "\n",
    "Wx_shared = theano.shared(\n",
    "            value=Wx,\n",
    "            name='Wx',\n",
    "            borrow=True\n",
    "        )\n",
    "\n",
    "Wh_shared = theano.shared(\n",
    "            value=Wh,\n",
    "            name='Wh',\n",
    "            borrow=True\n",
    "        )\n",
    "\n",
    "b_shared = theano.shared(\n",
    "            value=b,\n",
    "            name='b',\n",
    "            borrow=True\n",
    "        )\n",
    "\n",
    "def slice_add(x, prev_h, Wx, Wh, b):\n",
    "    next_h = T.tanh(T.dot(prev_h, Wh) + T.dot(x, Wx) + b)\n",
    "    return next_h\n",
    "\n",
    "result, _ = theano.scan(fn=lambda t, ht: slice_add(x[:, t, :], ht, Wx_shared, Wh_shared, b_shared),\n",
    "                        sequences=T.arange(TS),\n",
    "                        outputs_info=h0_shared)\n",
    "\n",
    "slice_x = theano.function(inputs=[x], outputs=result)\n",
    "\n",
    "final_res = slice_x(x_num)\n",
    "\n",
    "print(final_res.shape)\n",
    "\n",
    "print final_res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla RNN Forward\n",
    "\n",
    "Now we use `theano.scan()` to implement RNN forward over T sequence. It turns out we need quite some tricks to make this work smoothly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h error:  2.24007004401e-07\n"
     ]
    }
   ],
   "source": [
    "N, TS, D, H = 2, 3, 4, 5\n",
    "\n",
    "x = T.tensor3('x')\n",
    "\n",
    "x_num = np.asarray(np.linspace(-0.1, 0.3, num=N*TS*D).reshape(N, TS, D), dtype='float32')\n",
    "h0 = np.asarray(np.linspace(-0.3, 0.1, num=N*H).reshape(N, H), dtype='float32')\n",
    "Wx = np.asarray(np.linspace(-0.2, 0.4, num=D*H).reshape(D, H), dtype='float32')\n",
    "Wh = np.asarray(np.linspace(-0.4, 0.1, num=H*H).reshape(H, H), dtype='float32')\n",
    "b = np.asarray(np.linspace(-0.7, 0.1, num=H), dtype='float32')\n",
    "\n",
    "h0_shared = theano.shared(\n",
    "            value=h0,\n",
    "            name='h0',\n",
    "            borrow=True\n",
    "        )\n",
    "\n",
    "Wx_shared = theano.shared(\n",
    "            value=Wx,\n",
    "            name='Wx',\n",
    "            borrow=True\n",
    "        )\n",
    "\n",
    "Wh_shared = theano.shared(\n",
    "            value=Wh,\n",
    "            name='Wh',\n",
    "            borrow=True\n",
    "        )\n",
    "\n",
    "b_shared = theano.shared(\n",
    "            value=b,\n",
    "            name='b',\n",
    "            borrow=True\n",
    "        )\n",
    "\n",
    "rnn_hidden_states = rnn_forward(x, h0_shared, Wx_shared, Wh_shared, b_shared, (N, TS, H))\n",
    "\n",
    "expected_h = np.asarray([\n",
    "  [\n",
    "    [-0.42070749, -0.27279261, -0.11074945,  0.05740409,  0.22236251],\n",
    "    [-0.39525808, -0.22554661, -0.0409454,   0.14649412,  0.32397316],\n",
    "    [-0.42305111, -0.24223728, -0.04287027,  0.15997045,  0.35014525],\n",
    "  ],\n",
    "  [\n",
    "    [-0.55857474, -0.39065825, -0.19198182,  0.02378408,  0.23735671],\n",
    "    [-0.27150199, -0.07088804,  0.13562939,  0.33099728,  0.50158768],\n",
    "    [-0.51014825, -0.30524429, -0.06755202,  0.17806392,  0.40333043]]])\n",
    "\n",
    "get_h = theano.function(inputs=[x], outputs=rnn_hidden_states)\n",
    "\n",
    "h = get_h(x_num)\n",
    "\n",
    "print 'h error: ', rel_error(expected_h, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## LSTM: step forward\n",
    "\n",
    "Adapting one step LSTM to theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next_h error:  4.45981854665e-08\n",
      "next_c error:  4.49625600634e-08\n"
     ]
    }
   ],
   "source": [
    "N, D, H = 3, 4, 5\n",
    "\n",
    "x_sym = T.matrix('x')\n",
    "\n",
    "x = np.asarray(np.linspace(-0.4, 1.2, num=N*D).reshape(N, D), dtype='float32')\n",
    "prev_h = np.asarray(np.linspace(-0.3, 0.7, num=N*H).reshape(N, H), dtype='float32')\n",
    "prev_c = np.asarray(np.linspace(-0.4, 0.9, num=N*H).reshape(N, H), dtype='float32')\n",
    "Wx = np.asarray(np.linspace(-2.1, 1.3, num=4*D*H).reshape(D, 4 * H), dtype='float32')\n",
    "Wh = np.asarray(np.linspace(-0.7, 2.2, num=4*H*H).reshape(H, 4 * H), dtype='float32')\n",
    "b = np.asarray(np.linspace(0.3, 0.7, num=4*H), dtype='float32')\n",
    "\n",
    "prev_h_shared = theano.shared(\n",
    "            value=prev_h,\n",
    "            name='prev_h',\n",
    "            borrow=True\n",
    "        )\n",
    "               \n",
    "prev_c_shared = theano.shared(\n",
    "            value=prev_c,\n",
    "            name='prev_c',\n",
    "            borrow=True\n",
    "        )\n",
    "\n",
    "Wx_shared = theano.shared(\n",
    "            value=Wx,\n",
    "            name='Wx',\n",
    "            borrow=True\n",
    "        )\n",
    "\n",
    "Wh_shared = theano.shared(\n",
    "            value=Wh,\n",
    "            name='Wh',\n",
    "            borrow=True\n",
    "        )\n",
    "\n",
    "b_shared = theano.shared(\n",
    "            value=b,\n",
    "            name='b',\n",
    "            borrow=True\n",
    "        )\n",
    "\n",
    "next_h, next_c = lstm_step_forward(x_sym, prev_h, prev_c, Wx, Wh, b, H)\n",
    "               \n",
    "lstm_step_forward_num = theano.function(inputs=[x_sym], outputs=[next_h, next_c])\n",
    "\n",
    "next_h_num, next_c_num = lstm_step_forward_num(x)\n",
    "\n",
    "expected_next_h = np.asarray([\n",
    "    [ 0.24635157,  0.28610883,  0.32240467,  0.35525807,  0.38474904],\n",
    "    [ 0.49223563,  0.55611431,  0.61507696,  0.66844003,  0.7159181 ],\n",
    "    [ 0.56735664,  0.66310127,  0.74419266,  0.80889665,  0.858299  ]])\n",
    "expected_next_c = np.asarray([\n",
    "    [ 0.32986176,  0.39145139,  0.451556,    0.51014116,  0.56717407],\n",
    "    [ 0.66382255,  0.76674007,  0.87195994,  0.97902709,  1.08751345],\n",
    "    [ 0.74192008,  0.90592151,  1.07717006,  1.25120233,  1.42395676]])\n",
    "\n",
    "print 'next_h error: ', rel_error(expected_next_h, next_h_num)\n",
    "print 'next_c error: ', rel_error(expected_next_c, next_c_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla LSTM Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h error:  2.8783979953e-07\n"
     ]
    }
   ],
   "source": [
    "N, D, H, TS = 2, 5, 4, 3\n",
    "\n",
    "x_sym = T.tensor3('x')\n",
    "\n",
    "x = np.asarray(np.linspace(-0.4, 0.6, num=N*TS*D).reshape(N, TS, D), dtype='float32')\n",
    "h0 = np.asarray(np.linspace(-0.4, 0.8, num=N*H).reshape(N, H), dtype='float32')\n",
    "Wx = np.asarray(np.linspace(-0.2, 0.9, num=4*D*H).reshape(D, 4 * H), dtype='float32')\n",
    "Wh = np.asarray(np.linspace(-0.3, 0.6, num=4*H*H).reshape(H, 4 * H), dtype='float32')\n",
    "b = np.asarray(np.linspace(0.2, 0.7, num=4*H), dtype='float32')\n",
    "\n",
    "h0_shared = theano.shared(\n",
    "            value=h0,\n",
    "            name='h0',\n",
    "            borrow=True\n",
    "        )\n",
    "\n",
    "Wx_shared = theano.shared(\n",
    "            value=Wx,\n",
    "            name='Wx',\n",
    "            borrow=True\n",
    "        )\n",
    "\n",
    "Wh_shared = theano.shared(\n",
    "            value=Wh,\n",
    "            name='Wh',\n",
    "            borrow=True\n",
    "        )\n",
    "\n",
    "b_shared = theano.shared(\n",
    "            value=b,\n",
    "            name='b',\n",
    "            borrow=True\n",
    "        )\n",
    "\n",
    "h_sym = lstm_forward(x_sym, h0, Wx, Wh, b, (N, TS, H))\n",
    "\n",
    "get_lstm_forward_num = theano.function(inputs=[x_sym], outputs=[h_sym])\n",
    "\n",
    "h = get_lstm_forward_num(x)\n",
    "\n",
    "expected_h = np.asarray([\n",
    " [[ 0.01764008,  0.01823233,  0.01882671,  0.0194232 ],\n",
    "  [ 0.11287491,  0.12146228,  0.13018446,  0.13902939],\n",
    "  [ 0.31358768,  0.33338627,  0.35304453,  0.37250975]],\n",
    " [[ 0.45767879,  0.4761092,   0.4936887,   0.51041945],\n",
    "  [ 0.6704845,   0.69350089,  0.71486014,  0.7346449 ],\n",
    "  [ 0.81733511,  0.83677871,  0.85403753,  0.86935314]]])\n",
    "\n",
    "print 'h error: ', rel_error(expected_h, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inner Attention Layer\n",
    "\n",
    "Inner attention layer is a single layer that's on top of LSTM/RNN. This layer chanegs/recomputes the hidden state. This is from the paper [LSTMN on Machine Reading](http://arxiv.org/pdf/1601.06733v3.pdf). Inner attention layer can be implemented on both encoder and decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Attention Layer\n",
    "\n",
    "Global attention layer is very traditional, reference [Luong's paper](http://arxiv.org/pdf/1508.04025v5.pdf). They also implemented a local attention layer (which is very different from Inner attention layer, and more similar to hard vs. soft attention). We skip local attention layer in this build."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

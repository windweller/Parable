{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN-Sentence\n",
    "\n",
    "This notebook is used to test, load, and process CNN-sentence related data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/allen/miniconda2/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "from classifier.layers import *\n",
    "from data.sentence_util import *\n",
    "from vis.util import *\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "We are only using part of IMDB sentiment analysis dataset. We need to load in both data and an idxmap. Data are all preprocessed and stored. `maxlen` actually controls how many sentences we want. Watch out that everytime we load, the order of data will change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_val:  (244, 99)\n",
      "X_train:  (2200, 99)\n",
      "X_test:  (2543, 99)\n",
      "y_val:  (244,)\n",
      "y_train:  (2200,)\n",
      "y_test:  (2543,)\n",
      "====================\n",
      "word_emb:  (78271, 300)\n",
      "number of words:  78271\n"
     ]
    }
   ],
   "source": [
    "#prefix = \"/Users/Aimingnie/Documents/School/Stanford/CS 224N/DeepLearning/dataset/\"\n",
    "prefix = \"\"\n",
    "datapath = \"imdb_lstm.pkl\"\n",
    "idxmap = \"imdb_lstm.idxmap.pkl\"\n",
    "\n",
    "data = load_data(prefix+datapath,\n",
    "                       valid_portion=0.1,\n",
    "                       maxlen=100,\n",
    "                       permutation = False)\n",
    "word_emb, word_idx_map, idx_word_map = load_idx_map(prefix + idxmap)\n",
    "\n",
    "for k, v in data.iteritems():\n",
    "  print '%s: ' % k, v.shape\n",
    "\n",
    "print \"=\"*20\n",
    "\n",
    "print \"word_emb: \", word_emb.shape\n",
    "print \"number of words: \", len(word_idx_map.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB Movie Review: \n",
      "\n",
      "label:  1\n",
      "\n",
      "i liked the film some of the action scenes were very interesting , tense and well done i especially liked the opening scene which had a semi truck in it a very tense action scene that seemed well done br br some of the transitional scenes were filmed in interesting ways such as time lapse photography , unusual colors , or interesting angles also the film is funny is several parts i also liked how the evil guy was portrayed too i 'd give the film an 8 out of 10\n"
     ]
    }
   ],
   "source": [
    "# Visualize some examples from the dataset.\n",
    "# We show a few examples of training images from each class.\n",
    "print \"IMDB Movie Review: \"\n",
    "print\n",
    "print \"label: \", data['y_train'][0]\n",
    "print\n",
    "print decode_sentences(data['X_train'][0], idx_word_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv2d in Theano\n",
    "\n",
    "Learn about the function and what it does, and how to appropriately add padding for it. `border_mode=half` will keep the same size for odd-sized filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after applying 'full' border_mode padding, we get output size:\n",
      "intput:  (5, 1, 15, 15)\n",
      "output:  (5, 3, 17, 17)\n",
      "\n",
      "after applying 'valid' border_mode padding, we get output size:\n",
      "intput:  (5, 1, 15, 15)\n",
      "output:  (5, 3, 13, 13)\n",
      "\n",
      "after applying 'half' border_mode padding, we get output size:\n",
      "intput:  (5, 1, 15, 15)\n",
      "output:  (5, 3, 15, 15)\n",
      "\n",
      "after applying '(1,1)' custom padding border_mode padding, we get output size:\n",
      "intput:  (5, 1, 15, 15)\n",
      "output:  (5, 3, 15, 15)\n"
     ]
    }
   ],
   "source": [
    "from theano.tensor.nnet import conv2d\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "\n",
    "X = np.asarray(np.random.randn(5,1,15,15),dtype='float32') #N, C, H, W\n",
    "# filter weight\n",
    "w = theano.shared(\n",
    "            value=np.zeros((3,1,3,3), dtype='float32'),\n",
    "            name='filter1',\n",
    "            borrow=True\n",
    "        ) # num_filter = 3, prev-depth = 1, filter_size=3x3\n",
    "x = T.tensor4('x',dtype='float32')\n",
    "filtering = conv2d(x, w, border_mode='full', subsample=(1, 1)) #stride: 1,1\n",
    "f = theano.function([x], filtering)\n",
    "\n",
    "print \"after applying 'full' border_mode padding, we get output size:\"\n",
    "print \"intput: \", X.shape\n",
    "print \"output: \", f(X).shape\n",
    "\n",
    "filtering2 = conv2d(x, w, border_mode='valid', subsample=(1, 1)) #stride: 1,1\n",
    "f2 = theano.function([x], filtering2)\n",
    "\n",
    "print\n",
    "\n",
    "print \"after applying 'valid' border_mode padding, we get output size:\"\n",
    "print \"intput: \", X.shape\n",
    "print \"output: \", f2(X).shape\n",
    "\n",
    "filtering3 = conv2d(x, w, border_mode='half', subsample=(1, 1)) #stride: 1,1\n",
    "f3 = theano.function([x], filtering3)\n",
    "\n",
    "print \n",
    "\n",
    "print \"after applying 'half' border_mode padding, we get output size:\"\n",
    "print \"intput: \", X.shape\n",
    "print \"output: \", f3(X).shape\n",
    "\n",
    "filtering4 = conv2d(x, w, border_mode=(3, 3), subsample=(1, 1)) #stride: 1,1\n",
    "f4 = theano.function([x], filtering3)\n",
    "\n",
    "print \n",
    "print \"after applying '(1,1)' custom padding border_mode padding, we get output size:\"\n",
    "print \"intput: \", X.shape\n",
    "print \"output: \", f4(X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Conv Layer\n",
    "\n",
    "See if the implementation of `conv_layer()` is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 16, 32, 32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.asarray(np.random.randn(10,3,32,32),dtype='float32') #N, C, H, W\n",
    "# filter weight\n",
    "w = theano.shared(\n",
    "            value=np.zeros((16,3,3,3), dtype='float32'),\n",
    "            name='filter1',\n",
    "            borrow=True\n",
    "        ) # num_filter = 3, prev-depth = 1, filter_size=3x3\n",
    "b = theano.shared(\n",
    "            value=np.zeros(16, dtype='float32'),\n",
    "            name='b1',\n",
    "            borrow=True\n",
    "        )\n",
    "x = T.tensor4('x',dtype='float32')\n",
    "\n",
    "exp = conv_layer(x, w, b, {'stride': 1, 'pad': 1})\n",
    "f = theano.function([], exp, givens={x: X})\n",
    "print f().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Conv Net\n",
    "\n",
    "Testing the ConvNet() class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.6932049989700317, dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from classifier.layers import *\n",
    "import numpy as np\n",
    "import theano\n",
    "\n",
    "X = T.tensor4('X')  # data, presented as rasterized images\n",
    "y = T.ivector('y')\n",
    "\n",
    "X_train = np.asarray(np.random.randn(10,3,32,32), dtype='float32')\n",
    "y_train = np.asarray([1,0,0,0,1,1,1,0,0,1], dtype='int32')\n",
    "\n",
    "net = ConvNet(input_dim=(3,32,32))\n",
    "net.add_conv_relu_layer(16, 3, 1, 1, relu_a = 100)\n",
    "net.add_affine_softmax(net.prev_depth*net.affine_H*net.affine_W, 2)\n",
    "net.initialize()\n",
    "exp = net.loss(X, y)  # getting the loss expression\n",
    "\n",
    "f = theano.function([], exp, givens={X: X_train, y: y_train})\n",
    "f()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Parameter Update\n",
    "\n",
    "Since we are retrieving and assigning values to shared variables in solver.py, we should examine if they work.\n",
    "Be prepared this might cause problems/inefficiencies in GPU. Consider changing this in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_params = {}\n",
    "\n",
    "# get values out\n",
    "for k, v in net.params.iteritems():\n",
    "    best_params[k] = v.get_value(borrow=False)\n",
    "\n",
    "# update values\n",
    "for k, v in net.params.iteritems():\n",
    "    # borrow = True because we use numpy's buffer\n",
    "    net.params[k].set_value(best_params[k], borrow=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

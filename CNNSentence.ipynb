{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN-Sentence\n",
    "\n",
    "This notebook is used to test, load, and process CNN-sentence related data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from classifier.layers import *\n",
    "from data.data_util import *\n",
    "from vis.util import *\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "We are only using part of IMDB sentiment analysis dataset. We need to load in both data and an idxmap. Data are all preprocessed and stored. `maxlen` actually controls how many sentences we want. Watch out that everytime we load, the order of data will change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_val:  (244, 99)\n",
      "X_train:  (2200, 99)\n",
      "X_test:  (2543, 99)\n",
      "y_val:  (244,)\n",
      "y_train:  (2200,)\n",
      "y_test:  (2543,)\n",
      "====================\n",
      "word_emb:  (78271, 300)\n",
      "number of words:  78271\n"
     ]
    }
   ],
   "source": [
    "prefix = \"/Users/Aimingnie/Documents/School/Stanford/CS 224N/DeepLearning/dataset/\"\n",
    "datapath = \"imdb_lstm.pkl\"\n",
    "idxmap = \"imdb_lstm.idxmap.pkl\"\n",
    "\n",
    "data = load_data(prefix+datapath,\n",
    "                       valid_portion=0.1,\n",
    "                       maxlen=100,\n",
    "                       permutation = False)\n",
    "word_emb, word_idx_map, idx_word_map = load_idx_map(prefix + idxmap)\n",
    "\n",
    "for k, v in data.iteritems():\n",
    "  print '%s: ' % k, v.shape\n",
    "\n",
    "print \"=\"*20\n",
    "\n",
    "print \"word_emb: \", word_emb.shape\n",
    "print \"number of words: \", len(word_idx_map.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB Movie Review: \n",
      "\n",
      "label:  1\n",
      "\n",
      "i liked the film some of the action scenes were very interesting , tense and well done i especially liked the opening scene which had a semi truck in it a very tense action scene that seemed well done br br some of the transitional scenes were filmed in interesting ways such as time lapse photography , unusual colors , or interesting angles also the film is funny is several parts i also liked how the evil guy was portrayed too i 'd give the film an 8 out of 10\n"
     ]
    }
   ],
   "source": [
    "# Visualize some examples from the dataset.\n",
    "# We show a few examples of training images from each class.\n",
    "print \"IMDB Movie Review: \"\n",
    "print\n",
    "print \"label: \", data['y_train'][0]\n",
    "print\n",
    "print decode_sentences(data['X_train'][0], idx_word_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv2d in Theano\n",
    "\n",
    "Learn about the function and what it does, and how to appropriately add padding for it. `border_mode=half` will keep the same size for odd-sized filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after applying 'full' border_mode padding, we get output size:\n",
      "intput:  (5, 1, 15, 15)\n",
      "output:  (5, 3, 17, 17)\n",
      "\n",
      "after applying 'valid' border_mode padding, we get output size:\n",
      "intput:  (5, 1, 15, 15)\n",
      "output:  (5, 3, 13, 13)\n",
      "\n",
      "after applying 'half' border_mode padding, we get output size:\n",
      "intput:  (5, 1, 15, 15)\n",
      "output:  (5, 3, 15, 15)\n",
      "\n",
      "after applying '(1,1)' custom padding border_mode padding, we get output size:\n",
      "intput:  (5, 1, 15, 15)\n",
      "output:  (5, 3, 15, 15)\n"
     ]
    }
   ],
   "source": [
    "from theano.tensor.nnet import conv2d\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "\n",
    "X = np.asarray(np.random.randn(5,1,15,15),dtype='float32') #N, C, H, W\n",
    "# filter weight\n",
    "w = theano.shared(\n",
    "            value=np.zeros((3,1,3,3), dtype='float32'),\n",
    "            name='filter1',\n",
    "            borrow=True\n",
    "        ) # num_filter = 3, prev-depth = 1, filter_size=3x3\n",
    "x = T.tensor4('x',dtype='float32')\n",
    "filtering = conv2d(x, w, border_mode='full', subsample=(1, 1)) #stride: 1,1\n",
    "f = theano.function([x], filtering)\n",
    "\n",
    "print \"after applying 'full' border_mode padding, we get output size:\"\n",
    "print \"intput: \", X.shape\n",
    "print \"output: \", f(X).shape\n",
    "\n",
    "filtering2 = conv2d(x, w, border_mode='valid', subsample=(1, 1)) #stride: 1,1\n",
    "f2 = theano.function([x], filtering2)\n",
    "\n",
    "print\n",
    "\n",
    "print \"after applying 'valid' border_mode padding, we get output size:\"\n",
    "print \"intput: \", X.shape\n",
    "print \"output: \", f2(X).shape\n",
    "\n",
    "filtering3 = conv2d(x, w, border_mode='half', subsample=(1, 1)) #stride: 1,1\n",
    "f3 = theano.function([x], filtering3)\n",
    "\n",
    "print \n",
    "\n",
    "print \"after applying 'half' border_mode padding, we get output size:\"\n",
    "print \"intput: \", X.shape\n",
    "print \"output: \", f3(X).shape\n",
    "\n",
    "filtering4 = conv2d(x, w, border_mode=(3, 3), subsample=(1, 1)) #stride: 1,1\n",
    "f4 = theano.function([x], filtering3)\n",
    "\n",
    "print \n",
    "print \"after applying '(1,1)' custom padding border_mode padding, we get output size:\"\n",
    "print \"intput: \", X.shape\n",
    "print \"output: \", f4(X).shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Conv Net\n",
    "\n",
    "Building a conv net to train on sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W0': W0, 'b0': b0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from classifier.layers import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

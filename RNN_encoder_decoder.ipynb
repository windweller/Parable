{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Encoder-decoder\n",
    "\n",
    "This is the notebook for constructing Theano RNN encoder-decoder. The text for an encoder-decoder can be found in a lot of places, and one reference is here: [http://anie.me/rnn-encoder-decoder/](http://anie.me/rnn-encoder-decoder/). This notebook might also contain a section on vanilla RNN classification task, and a section on RNN autoencoder as well. Note in this implementation, we are being a lot more efficient than some blog posts (like in WildML)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from classifier.rnn_layers import *\n",
    "from classifier.util import *\n",
    "from data.snli_util import *\n",
    "from vis.util import *\n",
    "import numpy as np\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "  \"\"\" returns relative error \"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Loading Data SNLI\n",
    "\n",
    "We use SNLI for inference task (the main purpose of encoder-decoder). We use a partial IMDB dataset provided by Yoon Kim (also preprocessed into numpy form)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = load_data('data/snli_processed.npz')\n",
    "\n",
    "# NOTE: right now this doesn't work, but we want to hold it to \n",
    "# the same standard as other code\n",
    "# Print out all the keys and values from the data dictionary\n",
    "for k, v in data.iteritems():\n",
    "  if type(v) == np.ndarray:\n",
    "    print k, type(v), v.shape, v.dtype\n",
    "  else:\n",
    "    print k, type(v), len(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the Data\n",
    "\n",
    "All the sentences in train, dev, and test are encoded already by indicies. Now we see if we can successfully decode them into actual sentence with our `decode()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla RNN stepforward\n",
    "\n",
    "We implement the RNN for a single forward step in Theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " next_h error:  9.608901251e-08\n"
     ]
    }
   ],
   "source": [
    "N, D, H = 3, 10, 4\n",
    "\n",
    "x = np.asarray(np.linspace(-0.4, 0.7, num=N*D).reshape(N, D), dtype='float32')\n",
    "prev_h = np.asarray(np.linspace(-0.2, 0.5, num=N*H).reshape(N, H), dtype='float32')\n",
    "Wx = np.asarray(np.linspace(-0.1, 0.9, num=D*H).reshape(D, H), dtype='float32')\n",
    "Wh = np.asarray(np.linspace(-0.3, 0.7, num=H*H).reshape(H, H), dtype='float32')\n",
    "b = np.asarray(np.linspace(-0.2, 0.4, num=H), dtype='float32')\n",
    "\n",
    "x_sym = T.matrix('x')\n",
    "prev_h_shared = theano.shared(\n",
    "            value=prev_h,\n",
    "            name='prev_h',\n",
    "            borrow=True\n",
    "        )\n",
    "Wx_shared = theano.shared(\n",
    "            value=Wx,\n",
    "            name='Wx',\n",
    "            borrow=True\n",
    ")\n",
    "Wh_shared = theano.shared(\n",
    "            value=Wh,\n",
    "            name='Wh',\n",
    "            borrow=True\n",
    ")\n",
    "b_shared = theano.shared(\n",
    "            value=b,\n",
    "            name='b',\n",
    "            borrow=True\n",
    ")\n",
    "\n",
    "next_h = rnn_step_forward(x_sym, prev_h_shared, Wx_shared, Wh_shared, b_shared)\n",
    "\n",
    "get_value_nexth = theano.function([x_sym], next_h)\n",
    "\n",
    "expected_next_h = np.asarray([\n",
    "  [-0.58172089, -0.50182032, -0.41232771, -0.31410098],\n",
    "  [ 0.66854692,  0.79562378,  0.87755553,  0.92795967],\n",
    "  [ 0.97934501,  0.99144213,  0.99646691,  0.99854353]])\n",
    "\n",
    "print 'next_h error: ', rel_error(expected_next_h, get_value_nexth(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla RNN Forward\n",
    "\n",
    "Now we use `theano.scan()` to implement RNN forward over T sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
